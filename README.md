# eCommerce-Data-Pipeline-with-Snowflake-dbt
eCommerce data pipeline using Snowflake and dbt. Ingested raw CSVs, cleaned and transformed data with dbt models, and created analytics-ready datasets in the marts schema to enable faster insights and reporting.

---

## â¬…ï¸ Data Ingestion Process

- ğŸ“¤ **CSV files uploaded** to the Snowflake staging area.
- ğŸ§± **Snowflake tables created** for essential eCommerce entities:
  - Customers
  - Orders
  - Products
  - Payments

---

## ğŸ”§ Data Transformation with dbt

- ğŸ§¹ **Data Cleaning & Enrichment** using dbt models.
- âŒ **Critical error removal** and null value filtering.
- ğŸ”— **Data joins** to combine insights across entities.
- âœ… **Tested and version-controlled** transformation logic.

---

## ğŸ“Š Analysis & Reporting

- ğŸ“Œ Executed **SQL queries** for business insights.
- ğŸ§  Prepared analytics-ready datasets in the `marts` schema.
- ğŸ§¾ Enabled powerful reporting and dashboarding downstream.

---

## ğŸ’¼ Business Impact

- ğŸš€ **Streamlined end-to-end pipeline** from ingestion to analytics.
- ğŸ“ˆ Empowered **real-time decision-making** for eCommerce strategy.
- ğŸ’¡ Enabled scalable, consistent, and reproducible data transformations.

---

## ğŸ› ï¸ Technologies Used

| Tool        | Purpose                            |
|-------------|------------------------------------|
| Snowflake   | Cloud data warehouse               |
| dbt         | Data transformation & modeling     |
| SQL         | Data querying & analysis           |

---

## ğŸ“Œ Getting Started

### Prerequisites
- Snowflake account
- Python & dbt installed
- Access to raw CSV data

### Setup Steps
1. Upload your CSV files to the Snowflake staging area.
2. Create necessary Snowflake tables (DDL scripts included in `dbt_project/seeds` if applicable).
3. Initialize and run your dbt project:
   ```bash
   cd dbt_project
   dbt run
   dbt test
